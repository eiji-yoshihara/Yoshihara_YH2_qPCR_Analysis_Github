import io, os, zipfile, warnings, csv
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

st.set_page_config(page_title="Yoshihara Lab SOP Software YH#2 qPCR_Analysis_v0.1.2", layout="wide")
st.title("ğŸ§¬ Yoshihara Lab SOP Software YH#2 qPCR_Analysis_v0.1.2")

# ---------- Core helpers ----------
def read_qpcr_textfile(content_bytes: bytes) -> pd.DataFrame:
    # æ–‡å­—ã‚³ãƒ¼ãƒ‰: utf-8 â†’ cp932 ã®é †ã§è©¦ã™
    text = None
    for enc in ("utf-8", "cp932"):
        try:
            text = content_bytes.decode(enc)
            break
        except Exception:
            pass
    if text is None:
        raise ValueError("Encoding error (utf-8/cp932 Failed)")

    lines = text.splitlines()
    header_idx = next((i for i,l in enumerate(lines) if l.strip().startswith("Well")), None)
    if header_idx is None:
        raise ValueError("Header line 'Well ...' Not Found")
    data_str = "\n".join(lines[header_idx:])

    # åŒºåˆ‡ã‚Šæ¨å®š
    try:
        df = pd.read_csv(io.StringIO(data_str), sep="\t", engine="python")
        if df.shape[1] <= 1:
            raise ValueError
    except Exception:
        try:
            sniff = csv.Sniffer().sniff(data_str.split("\n",1)[0])
            sep = sniff.delimiter
        except Exception:
            sep = r"\s+"
        df = pd.read_csv(io.StringIO(data_str), sep=sep, engine="python")

    if "Reporter" in df.columns:
        df = df[df["Reporter"].astype(str)=="SYBR"]

    keep = ["Well","Sample Name","Detector Name","Reporter","Task","Ct","Quantity"]
    df = df.loc[:, [c for c in keep if c in df.columns]]
    return df

def clean_dataframe_for_analysis(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy(); df.columns = [c.strip() for c in df.columns]
    def _rn(target, cond):
        if target in df.columns: return
        cands = [c for c in df.columns if cond(c)]
        if cands: df.rename(columns={cands[0]:target}, inplace=True)
    _rn("Reporter", lambda c:c.lower()=="reporter")
    _rn("Ct", lambda c:c.lower()=="ct")
    _rn("Sample Name", lambda c:c.lower() in ("sample","sample_name","samplename"))
    _rn("Detector Name", lambda c:"detector" in c.lower())
    _rn("Task", lambda c:c.lower()=="task")
    _rn("Quantity", lambda c:"quantity" in c.lower())

    df["Ct"] = pd.to_numeric(df["Ct"].replace({"Undetermined":np.nan,"undetermined":np.nan}), errors="coerce")
    df["Quantity"] = pd.to_numeric(df.get("Quantity", np.nan), errors="coerce")
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        if "Well" in df.columns:
            df["Well"] = pd.to_numeric(df["Well"], errors="ignore")
    return df

def compute_standard_curve(df_std: pd.DataFrame):
    d = df_std.dropna(subset=["Ct","Quantity"]).copy()
    if len(d) < 2: return None
    X = np.log10(d["Quantity"].values).reshape(-1,1)
    y = d["Ct"].values
    model = LinearRegression().fit(X,y)
    r2 = r2_score(y, model.predict(X))
    return {"slope": float(model.coef_[0]), "intercept": float(model.intercept_), "r2": float(r2), "model": model}

def ct_to_quantity(ct, slope, intercept):
    if slope == 0 or np.isnan(slope): return np.nan
    return float(10 ** ((ct - intercept) / slope))

# ---------- State ----------
if "df_raw" not in st.session_state:
    st.session_state.update({
        "df_raw": None,
        "df_std_clean": None,
        "df_smp": None,
        "df_smp_updated": None,
        "conditions": ["Control","Treatment1","Treatment2"]
    })

# ---------- UI: Step tabs ----------
t1, t2, t3, t4, t5, t6 = st.tabs(["1) Upload", "2) Clean Standards", "3) Curves",
                                  "4) Assign", "5) Quantify", "6) Export"])

# 1) Upload â€”â€” è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œç‰ˆï¼ˆå®‰å®šåŒ–ï¼‰
with t1:
    ups = st.file_uploader(
        "ğŸ“„ Upload qPCR result files (multiple files allowed / TXT, TSV, CSV formats)",
        type=["txt", "tsv", "csv"],
        accept_multiple_files=True,
        key="uploader_multi",
        help="You can export a split from the same run or load multiple files together."
    )

    col_l, col_r = st.columns([1,1])
    load_clicked = col_l.button("Load file(s)")
    clear_clicked = col_r.button("Clear")

    if clear_clicked:
        st.session_state.df_raw = None
        st.experimental_rerun()

    if load_clicked:
        if not ups:
            st.warning("No file selected.")
        else:
            df_list = []
            errs = []
            for up in ups:
                try:
                    # ãƒã‚¤ãƒˆåˆ—ã‚’å®‰å…¨ã«å–å¾—ï¼ˆreadã‚ˆã‚ŠgetvalueãŒå …ç‰¢ï¼‰
                    content_bytes = up.getvalue()
                    df_tmp = read_qpcr_textfile(content_bytes)
                    df_tmp = clean_dataframe_for_analysis(df_tmp)
                    df_tmp["SourceFile"] = up.name
                    df_list.append(df_tmp)
                except Exception as e:
                    errs.append(f"{up.name}: {e}")

            if errs:
                st.error("Failed to load some of the files. See details below.â†“")
                st.code("\n".join(errs))

            if df_list:
                df = pd.concat(df_list, axis=0, ignore_index=True)
                df = df.dropna(how="all").reset_index(drop=True)
                st.session_state.df_raw = df
                st.success(f"Loaded {len(df_list)} file(s). Total rows = {len(df):,}")
            else:
                st.warning("No files could be read or recognized.")

    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ & å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
    if st.session_state.get("df_raw") is not None:
        st.caption("Preview of the beginning (up to 30 lines)")
        st.dataframe(st.session_state.df_raw.head(30), use_container_width=True)

        need = {"Task", "Ct", "Detector Name"}
        miss = [c for c in need if c not in st.session_state.df_raw.columns]
        if miss:
            st.error(f"Required column(s) missing: {miss}")
        else:
            cols = [c for c in ["Detector Name", "Task", "SourceFile"] if c in st.session_state.df_raw.columns]
            if cols:
                with st.expander("Summaryï¼ˆDetector/Task/SourceFileï¼‰", expanded=False):
                    st.write(
                        st.session_state.df_raw[cols]
                        .value_counts()
                        .reset_index(name="count")
                    )

# 2) Clean Standardsï¼ˆå„(Detector, Quantity)ã”ã¨ã«è¡Œãƒã‚§ãƒƒã‚¯â†’å‰Šé™¤ï¼‰
with t2:
    if st.session_state.df_raw is None:
        st.info("Please Complete Upload")
    else:
        # --- å…ƒãƒ‡ãƒ¼ã‚¿æ•´å½¢ ---
        df_std = st.session_state.df_raw.copy()
        df_std = df_std[
            df_std["Task"].astype(str).str.lower() == "standard"
        ].dropna(subset=["Ct"]).copy()

        if "Well" in df_std.columns:
            # æ•°å€¤åŒ–ï¼ˆå¤±æ•—ã¯NaNã®ã¾ã¾ï¼‰
            df_std["Well"] = pd.to_numeric(df_std["Well"], errors="coerce")

        # è¡¨ç¤ºé †
        df_std = df_std.sort_values(["Detector Name", "Quantity", "Well"], na_position="last")

        # --- å„ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã« expander ã§ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹è¡¨ç¤º ---
        drops = []  # å‰Šé™¤ã™ã‚‹ index ã‚’é›†ã‚ã‚‹
        for (det, qty), sub in df_std.groupby(["Detector Name", "Quantity"], dropna=False):
            ct_min, ct_max = sub["Ct"].min(), sub["Ct"].max()
            diff = float(ct_max - ct_min) if pd.notna(ct_min) and pd.notna(ct_max) else np.nan

            title = f"{det} : Quantity {qty}"
            if pd.notna(diff) and diff >= 1.5:
                title = f"âš ï¸ {title} (Î”Ct={diff:.2f})"

            with st.expander(title, expanded=False):
                st.caption("Please check the row(s) you would like to delete")
                # è¡Œã”ã¨ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
                sub_show = sub.reset_index()  # 'index' åˆ— = å…ƒã®è¡Œ index
                cols_to_show = ["Well", "Sample Name", "Ct"]
                st.dataframe(sub_show[cols_to_show + ["index"]].rename(columns={"index": "row_id"}),
                             use_container_width=True)

                # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ç¸¦ã«ä¸¦ã¹ã‚‹ï¼ˆIDã¯å…ƒ indexï¼‰
                for _, row in sub_show.iterrows():
                    lbl = f"{row.get('Sample Name','?')} (Ct={row.get('Ct')})"
                    ck_key = f"std_ck_{det}_{qty}_{int(row['index'])}"
                    checked = st.checkbox(lbl, key=ck_key, value=False)
                    if checked:
                        drops.append(int(row["index"]))

        # --- ç¢ºå®šãƒœã‚¿ãƒ³ ---
        if st.button("Apply cleaning", type="primary"):
            clean = df_std.drop(index=list(set(drops))).reset_index(drop=True)
            st.session_state.df_std_clean = clean
            st.success(f"Cleaned: {len(df_std)} â†’ {len(clean)} rows "
                       f"({len(set(drops))} row(s) removed)")
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        if st.session_state.get("df_std_clean") is not None:
            st.dataframe(st.session_state.df_std_clean.head(40), use_container_width=True)

# 3) Standard Curvesï¼ˆå …ç‰¢ç‰ˆï¼šQuantity>0 & finite ã®ã¿ä½¿ç”¨ã€æ¨™æº–ç‚¹>=2ï¼‰
with t3:
    if st.session_state.get("df_std_clean") is None:
        st.info("2) Please do Clean Standards")
    else:
        buf_pdf = io.BytesIO()
        with PdfPages(buf_pdf) as pdf:

            # æ—¢å­˜ã®ã‚¯ãƒªãƒ¼ãƒ³æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ Detector ã”ã¨ã«ä½œå›³
            for det in st.session_state.df_std_clean["Detector Name"].dropna().unique():
                raw = st.session_state.df_std_clean.copy()

                # å¿µã®ãŸã‚ Standard ã®ã¿ãƒ»Ct/Quantity ã®æœ‰é™å€¤ã®ã¿ãƒ»Quantity>0 ã«é™å®š
                ddf = raw[raw["Detector Name"] == det].copy()
                ddf = ddf.replace([np.inf, -np.inf], np.nan)
                ddf = ddf.dropna(subset=["Ct", "Quantity"])
                ddf = ddf[ddf["Quantity"] > 0]

                fig, ax = plt.subplots(figsize=(6, 4))
                ax.set_title(f"Standard curve: {det}")
                ax.set_xlabel("log10(Quantity)")
                ax.set_ylabel("Ct")

                if len(ddf) >= 2:
                    try:
                        x = np.log10(ddf["Quantity"].to_numpy())
                        y = ddf["Ct"].to_numpy()

                        # å¯è¦–åŒ–ï¼ˆæ•£å¸ƒå›³ï¼‰
                        ax.scatter(x, y, s=16, label="Data")

                        # ç·šå½¢å›å¸°
                        X = x.reshape(-1, 1)
                        model = LinearRegression().fit(X, y)
                        yhat = model.predict(X)
                        r2 = r2_score(y, yhat)
                        slope = float(model.coef_[0])
                        intercept = float(model.intercept_)

                        # ãƒ•ã‚£ãƒƒãƒˆç·š
                        xx = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)
                        yy = model.predict(xx)
                        ax.plot(xx.ravel(), yy, "--", linewidth=1.2, label="Fit")

                        # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
                        ax.text(
                            0.02, 0.02,
                            f"n={len(ddf)}\nslope={slope:.3f}\nRÂ²={r2:.3f}",
                            transform=ax.transAxes,
                            ha="left", va="bottom"
                        )

                        ax.legend(loc="best", fontsize=8)
                    except Exception as e:
                        ax.text(0.5, 0.5, f"Error in fit: {e}", ha="center")
                else:
                    ax.text(0.5, 0.5, "Insufficient standard points (n < 2)", ha="center")

                plt.tight_layout()
                st.pyplot(fig, clear_figure=True)
                pdf.savefig(fig)
                plt.close(fig)

        st.download_button(
            "ğŸ“„ Download standard-curve report (PDF)",
            data=buf_pdf.getvalue(),
            file_name="qpcr_standard_curve_report.pdf",
            mime="application/pdf",
        )

# 4) Assign
with t4:
    if st.session_state.df_raw is None:
        st.info("Please Complete Upload")
    else:
        # ---- å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆUnknown ã®ã¿ï¼‰ã‚’æ•´ãˆã‚‹ ----
        work = st.session_state.df_raw.copy()
        work = work[work["Task"].astype(str).str.lower() == "unknown"].copy()

        # ä¸¦ã³é †ï¼šDetectorâ†’Wellï¼ˆæ•°å€¤ã«ã§ãã‚‹å ´åˆï¼‰
        if "Well" in work.columns:
            work["Well"] = pd.to_numeric(work["Well"], errors="coerce")
            work = work.sort_values(["Detector Name", "Well"], na_position="last").reset_index(drop=False)
            # 'index' åˆ—ãŒå…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆã“ã®ç•ªå·ã§ assign_df ã‚’ç®¡ç†ï¼‰
            base_index = work["index"].to_list()
        else:
            work = work.sort_values(["Detector Name"]).reset_index(drop=False)
            base_index = work["index"].to_list()

        # ---- ã‚»ãƒƒã‚·ãƒ§ãƒ³å´ã®å‰²ã‚Šå½“ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆCondition/Replicateï¼‰ã‚’ç”¨æ„ ----
        if "assign_df" not in st.session_state:
            st.session_state.assign_df = pd.DataFrame(index=st.session_state.df_raw.index)
            st.session_state.assign_df["Condition"] = ""
            st.session_state.assign_df["Replicate"] = ""
        # Detector ãƒ†ãƒ³ãƒ—ãƒ¬ç”¨
        if "detector_template" not in st.session_state:
            st.session_state.detector_template = None

        # ---- Condition å€™è£œã‚’ç·¨é›† ----
        st.subheader("Define conditions")
        cond_text = st.text_area(
            "Conditions (1è¡Œã«1ã¤)",
            value="\n".join(st.session_state.get("conditions", ["Control", "Treatment1", "Treatment2"])),
            height=100,
            help="Editing the options here will also update the selections in the dropdown box below."
        )
        st.session_state.conditions = [c.strip() for c in cond_text.splitlines() if c.strip()]

        st.markdown("---")

        # ---- Detector ã”ã¨ã®å‰²ã‚Šå½“ã¦ UI ----
        for det in sorted(work["Detector Name"].dropna().unique().tolist()):
            with st.expander(f"Detector: {det}", expanded=False):
                sub = work[work["Detector Name"] == det].copy().reset_index(drop=True)
                # sub ã«ã¯ 'index' åˆ—ï¼ˆå…ƒ df_raw ã®è¡Œç•ªå·ï¼‰ãŒã‚ã‚‹

                # ====== ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆSample å / Well / Ctï¼‰ ======
                f1, f2, f3 = st.columns([2, 1, 1])
                with f1:
                    q = st.text_input("Filter (Sample/Well/Ct éƒ¨åˆ†ä¸€è‡´)", key=f"q_{det}").strip()
                with f2:
                    hide_nan = st.checkbox("Ct NaN ã‚’éš ã™", value=False, key=f"nan_{det}")
                with f3:
                    st.caption(f"Rows in this detector: {len(sub)}")

                filt = np.ones(len(sub), dtype=bool)
                if q:
                    qlow = q.lower()
                    filt &= (
                        sub["Sample Name"].astype(str).str.lower().str.contains(qlow) |
                        sub.get("Well", pd.Series([""] * len(sub))).astype(str).str.lower().str.contains(qlow) |
                        sub.get("Ct", pd.Series([""] * len(sub))).astype(str).str.lower().str.contains(qlow)
                    )
                if hide_nan and "Ct" in sub.columns:
                    filt &= sub["Ct"].notna()

                view = sub.loc[filt].copy()

                # ====== å¯¾è±¡è¡Œã®è¤‡æ•°é¸æŠ & å…¨é¸æŠ ======
                st.caption("Select samples to apply")
                # è¡¨ç¤ºãƒ©ãƒ™ãƒ«ã¨å…ƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆdf_raw ã®è¡Œç•ªå·ï¼‰ã‚’ãƒšã‚¢ã«
                options = [
                    (
                        f"{r['Sample Name']} (Well={'' if pd.isna(r.get('Well')) else int(r.get('Well')) if float(r.get('Well')).is_integer() else r.get('Well')}, Ct={r.get('Ct')})",
                        int(r["index"])
                    )
                    for _, r in view.iterrows()
                ]
                sel_key = f"ms_{det}"
                selected = st.multiselect(
                    "Samples",
                    [v for (_, v) in options],
                    format_func=lambda idx: next(lbl for (lbl, v) in options if v == idx),
                    key=sel_key
                )

                csel1, csel2 = st.columns([1, 1])
                if csel1.button("Select all (filtered)", key=f"selall_{det}"):
                    st.session_state[sel_key] = [v for (_, v) in options]
                    st.experimental_rerun()
                if csel2.button("Clear selection", key=f"selclr_{det}"):
                    st.session_state[sel_key] = []
                    st.experimental_rerun()

                # ====== Condition / Replicate ã‚’é¸ã³ã€é¸æŠè¡Œ or å…¨è¡Œã«é©ç”¨ ======
                c1, c2, c3, c4 = st.columns([2, 2, 2, 2])
                with c1:
                    pick_cond = st.selectbox("Condition", st.session_state.conditions, key=f"cond_{det}")
                with c2:
                    pick_rep = st.selectbox("Bio Rep", ["Rep1", "Rep2", "Rep3"], key=f"rep_{det}")
                with c3:
                    apply_clicked = st.button("Apply to selected", key=f"apply_{det}")
                with c4:
                    apply_all_clicked = st.button("Apply to ALL in this detector", key=f"applyall_{det}")

                if apply_clicked:
                    if not selected:
                        st.warning("No sample selected.")
                    else:
                        st.session_state.assign_df.loc[selected, ["Condition", "Replicate"]] = [pick_cond, pick_rep]
                        st.success(f"Applied to {len(selected)} row(s).")

                if apply_all_clicked:
                    locs = sub["index"].to_list()
                    st.session_state.assign_df.loc[locs, ["Condition", "Replicate"]] = [pick_cond, pick_rep]
                    st.success(f"Applied to ALL {len(locs)} row(s) in '{det}'.")

                # ====== Detector ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆã‚µã‚¤ã‚ºä¸€è‡´æ™‚ã®ã¿è²¼ä»˜ã‘ï¼‰ ======
                t1, t2 = st.columns([1, 1])
                if t1.button("Copy as template", key=f"copy_{det}"):
                    templ = st.session_state.assign_df.loc[sub["index"], ["Condition", "Replicate"]].copy().reset_index(drop=True)
                    st.session_state.detector_template = templ
                    st.success(f"Template copied from '{det}' ({len(templ)} rows).")

                if t2.button("Use the template", key=f"paste_{det}"):
                    templ = st.session_state.detector_template
                    tgt = st.session_state.assign_df.loc[sub["index"], ["Condition", "Replicate"]].copy().reset_index(drop=True)
                    if templ is None:
                        st.warning("No template copied yet.")
                    elif len(templ) != len(tgt):
                        st.warning(f"Template size mismatch: template={len(templ)} vs target={len(tgt)}")
                    else:
                        st.session_state.assign_df.loc[sub["index"], ["Condition", "Replicate"]] = templ.values
                        st.success(f"Template applied to '{det}'.")

                # ====== ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆç¾åœ¨ã®å‰²å½“ã¦ã‚’åæ˜ ã—ãŸè¡¨ï¼‰ ======
                st.caption("Updated table (after operations)")
                sub_preview = work[work["Detector Name"] == det][["index", "Sample Name", "Ct"]].copy()
                sub_preview["Condition"] = st.session_state.assign_df.loc[sub_preview["index"], "Condition"].values
                sub_preview["Replicate"] = st.session_state.assign_df.loc[sub_preview["index"], "Replicate"].values
                sub_preview = sub_preview.drop(columns=["index"])
                st.dataframe(sub_preview, use_container_width=True, hide_index=True)

        st.markdown("---")

        # ---- ä¿å­˜ï¼ˆæ¤œè¨¼ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¸ç¢ºå®šï¼‰ ----
        if st.button("Save assignment", type="primary", key="save_assign"):
            assigned = st.session_state.assign_df.copy()
            # Unknown å¯¾è±¡ã ã‘ã‚’æŠ½å‡º
            target_idx = st.session_state.df_raw.index[
                st.session_state.df_raw["Task"].astype(str).str.lower() == "unknown"
            ]
            # å¿…é ˆãƒã‚§ãƒƒã‚¯
            missing_mask = (assigned.loc[target_idx, "Condition"] == "") | (assigned.loc[target_idx, "Replicate"] == "")
            if missing_mask.any():
                miss_count = int(missing_mask.sum())
                st.error(f"{miss_count} samples missing assignment (Condition or Replicate).")
            else:
                # å…ƒãƒ‡ãƒ¼ã‚¿ã«åˆ—ãŒç„¡ã‘ã‚Œã°ä½œã‚‹
                if "Condition" not in st.session_state.df_raw.columns:
                    st.session_state.df_raw["Condition"] = ""
                if "Replicate" not in st.session_state.df_raw.columns:
                    st.session_state.df_raw["Replicate"] = ""

                # åæ˜ 
                st.session_state.df_raw.loc[:, "Condition"] = assigned["Condition"].fillna(st.session_state.df_raw["Condition"])
                st.session_state.df_raw.loc[:, "Replicate"] = assigned["Replicate"].fillna(st.session_state.df_raw["Replicate"])

                # å¾Œç¶šã‚¿ãƒ–ã§ä½¿ã† Unknown ã®å®Œæˆç‰ˆã‚’ä¿å­˜
                st.session_state.df_smp = st.session_state.df_raw[
                    st.session_state.df_raw["Task"].astype(str).str.lower() == "unknown"
                ].copy()

                st.success("Assignments saved.")

# 5) Quantifyï¼ˆUndetected ã¯ Quantity=0 ã¨ã—ã¦ä¿æŒã€‚ãŸã ã—çµ±è¨ˆãƒ»æç”»ã§ã¯ 0 ã‚’é™¤å¤–ï¼‰
with t5:
    if st.session_state.df_smp is None or st.session_state.df_std_clean is None:
        st.info("Please Complete 2) & 4)")
    else:
        # Ct â†’ Quantityï¼ˆCt æ¬ æ/Undetected ã¯ 0 æ‰±ã„ï¼‰
        def _ct_to_qty(ct, slope, intercept):
            if pd.isna(ct):
                return 0.0
            if slope == 0 or np.isnan(slope):
                return np.nan
            return float(10 ** ((ct - intercept) / slope))

        # 1) æ¨™æº–æ›²ç·šã‹ã‚‰ Quantity ã‚’ä»˜ä¸
        df_smp = st.session_state.df_smp.copy()
        df_smp["Quantity"] = np.nan

        for det in st.session_state.df_std_clean["Detector Name"].dropna().unique():
            dstd = st.session_state.df_std_clean[
                (st.session_state.df_std_clean["Detector Name"] == det) &
                (st.session_state.df_std_clean["Task"].astype(str).str.lower() == "standard")
            ].copy()

            # å®‰å…¨ã‚¬ãƒ¼ãƒ‰
            dstd = dstd.replace([np.inf, -np.inf], np.nan).dropna(subset=["Ct", "Quantity"])
            dstd = dstd[dstd["Quantity"] > 0]
            if len(dstd) < 2:
                st.warning(f"'{det}': Standard curve calculation skipped: fewer than 2 standard points or Quantity â‰¤ 0.")
                continue

            X = np.log10(dstd["Quantity"].to_numpy()).reshape(-1, 1)
            y = dstd["Ct"].to_numpy()
            model = LinearRegression().fit(X, y)
            slope = float(model.coef_[0]); intercept = float(model.intercept_)

            rows_all = (df_smp["Detector Name"] == det)
            df_smp.loc[rows_all, "Quantity"] = df_smp.loc[rows_all, "Ct"].apply(
                lambda c: _ct_to_qty(c, slope, intercept)
            )
            # éç‰©ç†å€¤ã¯ NaN
            df_smp.loc[rows_all & (df_smp["Quantity"] < 0), "Quantity"] = np.nan

        # 2) Control detector ã‚’é¸æŠã—ã¦ç›¸å¯¾é‡ã‚’è¨ˆç®—
        detectors_for_ctrl = sorted(df_smp["Detector Name"].dropna().unique().tolist())
        if not detectors_for_ctrl:
            st.error("Detector Name was not found. Please check Upload/Assign")
        else:
            ctrl_det = st.selectbox("Control detector", detectors_for_ctrl, key="ctrl_det_select")

            if st.button("Run Relative Quantification"):
                # Control ã® Quantityï¼ˆåˆ†æ¯å€™è£œï¼‰
                ctrl_df = (
                    df_smp[df_smp["Detector Name"] == ctrl_det][["Condition", "Replicate", "Quantity"]]
                    .rename(columns={"Quantity": "Ctrl_Quantity"})
                    .copy()
                )
                # åˆ†æ¯ 0/NaN/è² ã¯ç„¡åŠ¹ï¼ˆã‚¼ãƒ­å‰²å›é¿ï¼‰
                ctrl_df.loc[
                    (ctrl_df["Ctrl_Quantity"].isna()) | (ctrl_df["Ctrl_Quantity"] <= 0),
                    "Ctrl_Quantity"
                ] = np.nan

                # Fallback: Condition å¹³å‡ï¼ˆ>0 ã®ã¿ãŒå¹³å‡ã«å¯„ä¸ï¼‰
                ctrl_cond_mean = (
                    ctrl_df.groupby("Condition", as_index=False)["Ctrl_Quantity"]
                    .mean()
                    .rename(columns={"Ctrl_Quantity": "Ctrl_Cond_Mean"})
                )

                # ä½œæ¥­ãƒ†ãƒ¼ãƒ–ãƒ«
                df_temp = df_smp.copy()
                if "Relative Quantity" not in df_temp.columns:
                    df_temp["Relative Quantity"] = np.nan

                # å„ Detector ã«ã¤ã„ã¦ç›¸å¯¾é‡ã‚’è¨ˆç®—ï¼ˆåŒä¸€ Condition & Replicate ã‚’å¯¾å¿œä»˜ã‘ï¼‰
                for det in df_temp["Detector Name"].dropna().unique():
                    mask = (df_temp["Detector Name"] == det)
                    ddet = (
                        df_temp.loc[mask, ["Condition", "Replicate", "Quantity"]]
                        .reset_index()
                        .rename(columns={"index": "orig_index"})
                    )

                    merged = ddet.merge(ctrl_df, on=["Condition", "Replicate"], how="left")

                    # Ctrl ãŒæ¬ ã‘ãŸè¡Œã¯ Condition å¹³å‡ã§è£œå®Œ
                    if merged["Ctrl_Quantity"].isna().any():
                        merged = merged.merge(ctrl_cond_mean, on="Condition", how="left")
                        merged["Used_Ctrl"] = merged["Ctrl_Quantity"].fillna(merged["Ctrl_Cond_Mean"])
                    else:
                        merged["Used_Ctrl"] = merged["Ctrl_Quantity"]

                    # åˆ†å­ã‚‚ 0/NaN/è² ã¯ç„¡åŠ¹ï¼ˆ0 ã¯ã€Œéæ¤œå‡ºã€ã¨ã—ã¦é™¤å¤–ï¼‰
                    invalid_den = merged["Used_Ctrl"].isna() | (merged["Used_Ctrl"] <= 0)
                    invalid_num = merged["Quantity"].isna() | (merged["Quantity"] <= 0)

                    merged["Relative Quantity"] = np.where(
                        invalid_den | invalid_num,
                        np.nan,
                        merged["Quantity"] / merged["Used_Ctrl"]
                    )

                    # åæ˜ 
                    df_temp.loc[merged["orig_index"], "Relative Quantity"] = merged["Relative Quantity"].values

                # â˜… ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«éºä¼å­ã¯å¸¸ã« 1ï¼ˆQuantity>0 ã®è¡Œï¼‰ã€‚0/NaNè¡Œã¯ NaN ã®ã¾ã¾
                df_temp.loc[
                    (df_temp["Detector Name"] == ctrl_det) & (df_temp["Quantity"] > 0),
                    "Relative Quantity"
                ] = 1.0

                # 3) æŠ€è¡“åå¾©ï¼ˆReplicateï¼‰ãƒ¬ãƒ™ãƒ«ã®å¹³å‡ãƒ»SEM ã‚’ä½œæˆ
                #    â†’ 0ï¼ˆéæ¤œå‡ºç”±æ¥ï¼‰ã¯é™¤å¤–ã™ã‚‹ãŸã‚ã€Relative Quantity > 0 ã®ã¿æ¡ç”¨
                relq_valid = df_temp[["Detector Name", "Condition", "Replicate", "Relative Quantity"]].copy()
                relq_valid = relq_valid.dropna(subset=["Relative Quantity"])
                relq_valid = relq_valid[relq_valid["Relative Quantity"] > 0]

                stats = (
                    relq_valid.groupby(["Detector Name", "Condition", "Replicate"], observed=False)["Relative Quantity"]
                    .agg(RelQ_Mean="mean",
                         RelQ_SEM=lambda s: s.std(ddof=1) / np.sqrt(s.count()) if s.count() > 1 else 0.0)
                    .reset_index()
                )

                # å…ƒã«ãƒãƒ¼ã‚¸ï¼ˆç„¡åŠ¹ã‚»ãƒ«ã¯ RelQ_Mean/SEM ãŒæ¬ æã®ã¾ã¾ï¼‰
                st.session_state.df_smp_updated = df_temp.merge(
                    stats, on=["Detector Name", "Condition", "Replicate"], how="left"
                )

                st.success("Relative quantification done.")
                # å‚è€ƒï¼šé NaN ã®ç›¸å¯¾é‡ã‚«ã‚¦ãƒ³ãƒˆ
                dbg = st.session_state.df_smp_updated.groupby("Detector Name")["Relative Quantity"].apply(
                    lambda s: int(s.notna().sum())
                )
                st.caption("Non-NaN Relative Quantity count per detector")
                st.write(dbg)

        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        if st.session_state.get("df_smp_updated") is not None:
            st.dataframe(st.session_state.df_smp_updated.head(30), use_container_width=True)

# 6) Exportï¼ˆPDF: 2inÃ—2in ã‚°ãƒªãƒƒãƒ‰ & Standardã‚«ãƒ¼ãƒ–PDFã‚‚åŒæ¢± / UIã«ã‚‚ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰
with t6:
    if st.session_state.df_smp_updated is None:
        st.info("Please proceed with 5)")
    else:
        import io, zipfile
        from matplotlib.backends.backend_pdf import PdfPages

        # ---- æ—¥ä»˜å…¥ã‚Šãƒ™ãƒ¼ã‚¹å ----
        today = pd.Timestamp.now().strftime("%Y-%m-%d")
        base_name = f"{today}qPCR_Results"

        # ---- æç”»ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆç›¸å¯¾é‡ï¼šãƒãƒ¼Â±SEMï¼‹Repé»’ãƒ‰ãƒƒãƒˆï¼‰
        # 0 ã¯çµ±è¨ˆã‹ã‚‰é™¤å¤–ã™ã‚‹ãŒã€æç”»ã¯ 0 ãƒãƒ¼ã‚’å‡ºã™ï¼ˆã‚«ãƒ†ã‚´ãƒªã‚’æ¶ˆã•ãªã„ï¼‰
        def draw_relq_panel(ax, ddf, conds):
            vals = ddf[["Condition", "Replicate", "Relative Quantity"]].copy()

            # Repã”ã¨ã®å¹³å‡ï¼ˆ0 ã¯çµ±è¨ˆã‹ã‚‰é™¤å¤–ï¼‰
            rep_means = (
                vals[vals["Relative Quantity"] > 0]
                .groupby(["Condition", "Replicate"], observed=False)["Relative Quantity"]
                .mean()
                .reset_index(name="Rep_Mean")
            )

            # Conditionã”ã¨ã® Mean/SEM ã‚’ç®—å‡ºã€‚reindex ã§å…¨æ¡ä»¶ã‚’ä¿æŒ
            if not rep_means.empty:
                cond_stats = (
                    rep_means.groupby("Condition", observed=False)["Rep_Mean"]
                    .agg(Mean="mean", SEM=lambda s: s.std(ddof=1) / np.sqrt(s.count()))
                    .reindex(conds)
                )
            else:
                cond_stats = pd.DataFrame(index=conds, data={"Mean": np.nan, "SEM": np.nan})

            # æç”»ã¯ 0 ã§åŸ‹ã‚ã¦ãƒãƒ¼ã‚’å¿…ãšè¡¨ç¤º
            plot_means = cond_stats["Mean"].fillna(0.0).to_numpy()
            plot_sems = cond_stats["SEM"].fillna(0.0).to_numpy()
            xlabels = cond_stats.index.tolist()

            ax.bar(
                xlabels, plot_means,
                yerr=plot_sems, capsize=2, alpha=0.65, linewidth=0.4,
                error_kw={"elinewidth": 0.25, "capthick": 0.25}
            )

            # é»’ãƒ‰ãƒƒãƒˆï¼ˆRep_Meanï¼‰ã€‚0 ã¯çµ±è¨ˆã‹ã‚‰é™¤å¤–ã—ãŸã¾ã¾
            cond_to_x = {c: i for i, c in enumerate(xlabels)}
            rep_offset = {"Rep1": -0.12, "Rep2": 0.0, "Rep3": 0.12}
            for _, row in rep_means.iterrows():
                x = cond_to_x.get(row["Condition"], None)
                if x is None:
                    continue
                off = rep_offset.get(str(row["Replicate"]), 0.0)
                ax.scatter(x + off, row["Rep_Mean"], s=18, zorder=3, color="black")

            ax.set_ylabel("Relative Quantity", fontsize=8)
            ax.set_ylim(bottom=0)
            ax.tick_params(axis="x", labelrotation=45, labelsize=7)
            ax.tick_params(axis="y", labelsize=7)
            for spine in ax.spines.values():
                spine.set_linewidth(0.4)
            return True

        # ---- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ2in x 2in ã®ã‚¿ã‚¤ãƒ«ï¼‰----
        NCOLS, NROWS = 4, 3             # 1ãƒšãƒ¼ã‚¸12é¢
        PANEL_W, PANEL_H = 2.0, 2.0     # å„ãƒ‘ãƒãƒ« 2inå››æ–¹
        FIG_W, FIG_H = NCOLS * PANEL_W, NROWS * PANEL_H

        dets = st.session_state.df_smp_updated["Detector Name"].dropna().unique().tolist()
        conds = st.session_state.conditions

        # A) ç›¸å¯¾é‡ã‚°ãƒªãƒƒãƒ‰ PDF + UIãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        relq_pdf_buf = io.BytesIO()
        relq_page_pngs = []
        with PdfPages(relq_pdf_buf) as pdf:
            panel_i = 0
            fig = None
            axs = None
            for det in dets:
                if panel_i % (NCOLS * NROWS) == 0:
                    if fig is not None:
                        fig.tight_layout(pad=0.8)
                        pdf.savefig(fig)
                        buf_png = io.BytesIO()
                        fig.savefig(buf_png, format="png", dpi=200, bbox_inches="tight")
                        relq_page_pngs.append(buf_png.getvalue())
                        plt.close(fig)
                    fig, ax_grid = plt.subplots(NROWS, NCOLS, figsize=(FIG_W, FIG_H))
                    axs = ax_grid.flatten()

                ax = axs[panel_i % (NCOLS * NROWS)]
                ddf = st.session_state.df_smp_updated[
                    st.session_state.df_smp_updated["Detector Name"] == det
                ].copy()
                draw_relq_panel(ax, ddf, conds)
                ax.set_title(det, fontsize=9)
                panel_i += 1

            # æœ€å¾Œã®ãƒšãƒ¼ã‚¸ã‚’ flush
            if fig is not None:
                used = panel_i % (NCOLS * NROWS) or (NCOLS * NROWS)
                if used < (NCOLS * NROWS):
                    for k in range(used, NCOLS * NROWS):
                        axs[k].axis("off")
                fig.tight_layout(pad=0.8)
                pdf.savefig(fig)
                buf_png = io.BytesIO()
                fig.savefig(buf_png, format="png", dpi=200, bbox_inches="tight")
                relq_page_pngs.append(buf_png.getvalue())
                plt.close(fig)

        # B) Standardã‚«ãƒ¼ãƒ– PDF + UIãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        std_pdf_buf = io.BytesIO()
        std_page_pngs = []
        with PdfPages(std_pdf_buf) as pdf:
            if st.session_state.df_std_clean is not None and not st.session_state.df_std_clean.empty:
                panel_i = 0
                fig = None
                axs = None
                for det in st.session_state.df_std_clean["Detector Name"].dropna().unique():
                    ddf = st.session_state.df_std_clean[
                        st.session_state.df_std_clean["Detector Name"] == det
                    ].copy()
                    dwork = ddf.replace([np.inf, -np.inf], np.nan).dropna(subset=["Ct", "Quantity"])
                    dwork = dwork[dwork["Quantity"] > 0]
                    if len(dwork) < 2:
                        continue

                    X = np.log10(dwork["Quantity"].to_numpy()).reshape(-1, 1)
                    y = dwork["Ct"].to_numpy()
                    model = LinearRegression().fit(X, y)
                    slope = float(model.coef_[0])
                    intercept = float(model.intercept_)
                    r2 = r2_score(y, model.predict(X))

                    if panel_i % (NCOLS * NROWS) == 0:
                        if fig is not None:
                            fig.tight_layout(pad=0.8)
                            pdf.savefig(fig)
                            buf_png = io.BytesIO()
                            fig.savefig(buf_png, format="png", dpi=200, bbox_inches="tight")
                            std_page_pngs.append(buf_png.getvalue())
                            plt.close(fig)
                        fig, ax_grid = plt.subplots(NROWS, NCOLS, figsize=(FIG_W, FIG_H))
                        axs = ax_grid.flatten()

                    ax = axs[panel_i % (NCOLS * NROWS)]
                    x = np.log10(dwork["Quantity"])
                    yv = dwork["Ct"]
                    ax.scatter(x, yv, s=10, color="black")
                    xx = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)
                    ax.plot(xx, model.predict(xx), "--", linewidth=0.8, color="black")
                    ax.set_title(f"{det}\nslope={slope:.3f}, RÂ²={r2:.3f}", fontsize=8)
                    ax.set_xlabel("log10(Quantity)", fontsize=7)
                    ax.set_ylabel("Ct", fontsize=7)
                    ax.tick_params(labelsize=7)
                    for spine in ax.spines.values():
                        spine.set_linewidth(0.4)
                    panel_i += 1

                if fig is not None:
                    used = panel_i % (NCOLS * NROWS) or (NCOLS * NROWS)
                    if used < (NCOLS * NROWS):
                        for k in range(used, NCOLS * NROWS):
                            axs[k].axis("off")
                    fig.tight_layout(pad=0.8)
                    pdf.savefig(fig)
                    buf_png = io.BytesIO()
                    fig.savefig(buf_png, format="png", dpi=200, bbox_inches="tight")
                    std_page_pngs.append(buf_png.getvalue())
                    plt.close(fig)

        # C) CSV
        buf_csv = io.StringIO()
        st.session_state.df_smp_updated.to_csv(buf_csv, index=False)

        # D) ZIPï¼ˆç›¸å¯¾é‡ã‚°ãƒªãƒƒãƒ‰PDF + Standardã‚«ãƒ¼ãƒ–PDF + CSVï¼‰
        zip_buf = io.BytesIO()
        with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
            zf.writestr(f"{base_name}_grid2x2.pdf", relq_pdf_buf.getvalue())
            zf.writestr(f"{base_name}_standard_curves.pdf", std_pdf_buf.getvalue())
            zf.writestr(f"{base_name}.csv", buf_csv.getvalue())

        st.download_button(
            "ğŸ“¦ Download results (ZIP)",
            data=zip_buf.getvalue(),
            file_name=f"{base_name}.zip",
            mime="application/zip"
        )

        # E) UI ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆPDFã¨åŒã˜ãƒšãƒ¼ã‚¸ã‚’PNGã§è¡¨ç¤ºï¼‰
        st.subheader("ğŸ“„ Relative expression (grid) preview")
        if relq_page_pngs:
            for i, png in enumerate(relq_page_pngs, start=1):
                st.image(png, caption=f"RelQ grid page {i}", use_column_width=True)
        else:
            st.info("There are no pages available for display in the RelQ grid.")

        st.subheader("ğŸ“„ Standard curves preview")
        if std_page_pngs:
            for i, png in enumerate(std_page_pngs, start=1):
                st.image(png, caption=f"Standard curves page {i}", use_column_width=True)
        else:
            st.info("There are no pages available for display in the Standard Curves section.")
